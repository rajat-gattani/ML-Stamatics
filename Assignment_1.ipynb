{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f5e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b209b50",
   "metadata": {},
   "source": [
    "Q1 Let x = np.arange(4, dtype=np.int64). Create an array of ones with the same shape and type as X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729dc9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(4, dtype=np.int64)\n",
    "np.ones_like(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9ea803",
   "metadata": {},
   "source": [
    "Q2 Let X = np.array([[1, 2], [3, 4]]). Convert it into a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e39b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4]])\n",
    "np.asmatrix(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1fc004",
   "metadata": {},
   "source": [
    "Q3 Create a 1-D array of 50 evenly spaced elements between 3. and 10., inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0a47db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.        ,  3.14285714,  3.28571429,  3.42857143,  3.57142857,\n",
       "        3.71428571,  3.85714286,  4.        ,  4.14285714,  4.28571429,\n",
       "        4.42857143,  4.57142857,  4.71428571,  4.85714286,  5.        ,\n",
       "        5.14285714,  5.28571429,  5.42857143,  5.57142857,  5.71428571,\n",
       "        5.85714286,  6.        ,  6.14285714,  6.28571429,  6.42857143,\n",
       "        6.57142857,  6.71428571,  6.85714286,  7.        ,  7.14285714,\n",
       "        7.28571429,  7.42857143,  7.57142857,  7.71428571,  7.85714286,\n",
       "        8.        ,  8.14285714,  8.28571429,  8.42857143,  8.57142857,\n",
       "        8.71428571,  8.85714286,  9.        ,  9.14285714,  9.28571429,\n",
       "        9.42857143,  9.57142857,  9.71428571,  9.85714286, 10.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(3., 10, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289d659",
   "metadata": {},
   "source": [
    "Q4 Let x be array [[1, 2, 3], [4, 5, 6]]. Convert it to [1 4 2 5 3 6]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8435bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 2 5 3 6]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "out1 = np.ravel(x, order='F')\n",
    "out2 = x.flatten(order=\"F\")\n",
    "assert np.allclose(out1, out2)\n",
    "print (out1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71988acd",
   "metadata": {},
   "source": [
    "Q5 Let x be an array [1, 2, 3, ..., 9]. Split x into 3 arrays, each of which has 4, 2, and 3 elements in the original order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9425a232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1, 2, 3, 4]), array([5, 6]), array([7, 8, 9])]\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(1, 10)\n",
    "print (np.split(x, [4, 6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aecae8c",
   "metadata": {},
   "source": [
    " Q6 Compute the inverse and primary diagnol sum of x=[[1,2],[3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d79a142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]] 5.0\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1., 2.], [3., 4.]])\n",
    "out1 = np.linalg.inv(x)\n",
    "assert np.allclose(np.dot(x, out1), np.eye(2))\n",
    "print (out1,np.trace(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f088694",
   "metadata": {},
   "source": [
    "Q7 Sort x along the second axis. x = [[1,4],[3,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40099735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [1 3]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,4],[3,1]])\n",
    "out = np.sort(x, axis=1)\n",
    "x.sort(axis=1)\n",
    "assert np.array_equal(out, x)\n",
    "print (out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cc1a71",
   "metadata": {},
   "source": [
    "Q8 Get the indices that would sort x(as above) along the second axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f314f2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,4],[3,1]])\n",
    "out = np.argsort(x, axis=1)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf5455c",
   "metadata": {},
   "source": [
    "Initiate x as a 2x5 array with random values from 0 to 10(not inclusive).Get the maximum and minimum values and their indices of x along the second axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c9518c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [[6 4 0 9 2]\n",
      " [8 3 5 1 7]]\n",
      "maximum values = [9 8]\n",
      "max indices = [3 0]\n",
      "minimum values = [0 1]\n",
      "min indices = [2 3]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.permutation(10).reshape(2, 5)\n",
    "print (\"x =\", x)\n",
    "print (\"maximum values =\", np.max(x, 1))\n",
    "print (\"max indices =\", np.argmax(x, 1))\n",
    "print (\"minimum values =\", np.min(x, 1))\n",
    "print (\"min indices =\", np.argmin(x, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c46002",
   "metadata": {},
   "source": [
    "Run the following load command to get the 2-Dim iris dataset. Do the following operations on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d70b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bd05b0",
   "metadata": {},
   "source": [
    "Drop rows that contain a missing value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ffd754b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1:\n",
    "any_nan_in_row = np.array([~np.any(np.isnan(row)) for row in iris_2d])\n",
    "iris_2d[any_nan_in_row]\n",
    "\n",
    "# Method 2: (By Rong)\n",
    "iris_2d[np.sum(np.isnan(iris_2d), axis = 1) == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd9fb3",
   "metadata": {},
   "source": [
    "Find the correlation between first two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3ef5a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8717541573048718"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(iris_2d[:, 0], iris_2d[:, 2])[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73965a4a",
   "metadata": {},
   "source": [
    "Find the mean,median and standard deviation of column 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab824597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.35 2.25 1.7298843892006195\n"
     ]
    }
   ],
   "source": [
    "mu, med, sd = np.mean(iris_2d[2]), np.median(iris_2d[2]), np.std(iris_2d[2])\n",
    "print(mu, med, sd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e0308e",
   "metadata": {},
   "source": [
    "Create a new column for volume in iris_2d, where volume is (pi x petallength x sepal_length^2)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "91c944c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1       ,  3.5       ,  1.4       ,  0.2       , 38.13265163],\n",
       "       [ 4.9       ,  3.        ,  1.4       ,  0.2       , 35.20049849],\n",
       "       [ 4.7       ,  3.2       ,  1.3       ,  0.2       , 30.07237208],\n",
       "       [ 4.6       ,  3.1       ,  1.5       ,  0.2       , 33.23805027]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepallength = iris_2d[:, 0].astype('float')\n",
    "petallength = iris_2d[:, 2].astype('float')\n",
    "volume = (np.pi * petallength * (sepallength**2))/3\n",
    "\n",
    "# Introduce new dimension to match iris_2d's\n",
    "volume = volume[:, np.newaxis]\n",
    "\n",
    "# Add the new column\n",
    "out = np.hstack([iris_2d, volume])\n",
    "\n",
    "# View\n",
    "out[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c1758f",
   "metadata": {},
   "source": [
    "Run the following loaad command and solve the following questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3fae8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris = np.genfromtxt(url, delimiter=',', dtype='object')\n",
    "names = ('sepallength', 'sepalwidth', 'petallength', 'petalwidth', 'species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee21e50",
   "metadata": {},
   "source": [
    "Find the count of unique species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "730ad758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([b'Iris-setosa', b'Iris-versicolor', b'Iris-virginica'],\n",
       "       dtype='|S15'),\n",
       " array([50, 50, 50], dtype=int64))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = np.array([row.tolist()[4] for row in iris])\n",
    "np.unique(species, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d054b10",
   "metadata": {},
   "source": [
    "Bin the petal length (3rd) column of iris_2d to form a text array, such that if petal length is:\n",
    "Less than 3 –> ‘small’\n",
    "3-5 –> ‘medium’\n",
    "‘>=5 –> ‘large’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5be1b28a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'small',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'large',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'large',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'medium',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'medium',\n",
       " 'large',\n",
       " 'medium',\n",
       " 'large',\n",
       " 'large',\n",
       " 'medium',\n",
       " 'medium',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'medium',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large',\n",
       " 'large']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "petal_length_bin = np.digitize(iris[:, 2].astype('float'), [0, 3, 5, 10])\n",
    "\n",
    "# Map it to respective category\n",
    "label_map = {1: 'small', 2: 'medium', 3: 'large', 4: np.nan}\n",
    "petal_length_cat = [label_map[x] for x in petal_length_bin]\n",
    "\n",
    "# View\n",
    "petal_length_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b2ddd8",
   "metadata": {},
   "source": [
    "Find the most frequent value of petal length (3rd column) in iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb79857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'1.5'\n"
     ]
    }
   ],
   "source": [
    "vals, counts = np.unique(iris[:,2], return_counts=True)\n",
    "print(vals[np.argmax(counts)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
